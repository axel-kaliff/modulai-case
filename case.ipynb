{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58ac429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ee07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(data_path: str = 'data/filtered'):\n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    movies_df = pd.read_csv(data_path / 'movies.csv')\n",
    "    actors_df = pd.read_csv(data_path / 'actors.csv')\n",
    "    directors_df = pd.read_csv(data_path / 'directors.csv')\n",
    "    studios_df = pd.read_csv(data_path / 'studios.csv')\n",
    "    \n",
    "    poster_embeddings = np.load(data_path / 'poster_embeddings.npy')\n",
    "    tagline_embeddings = np.load(data_path / 'tagline_embeddings.npy')\n",
    "    description_embeddings = np.load(data_path / 'description_embeddings.npy')\n",
    "    \n",
    "    return movies_df, actors_df, directors_df, studios_df, poster_embeddings, tagline_embeddings, description_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac08daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(movies_df, actors_df, directors_df, studios_df):\n",
    "\n",
    "    features = movies_df[['movie_id']].copy()\n",
    "    \n",
    "    # normalize numerical features\n",
    "    features['year'] = movies_df['date']\n",
    "    features['runtime'] = movies_df['minute']\n",
    "    features['year_normalized'] = (features['year'] - features['year'].mean()) / features['year'].std()\n",
    "    features['runtime_normalized'] = (features['runtime'] - features['runtime'].mean()) / features['runtime'].std()\n",
    "    \n",
    "    # one-hot encoding age rating\n",
    "    age_dummies = pd.get_dummies(movies_df['theatrical_release_age_rating'], prefix='age_rating', dummy_na=True)\n",
    "    features = pd.concat([features, age_dummies], axis=1)\n",
    "    \n",
    "    # encoding actors, directors, studios as binary features\n",
    "    top_actors = actors_df['actor_name'].value_counts().head(50).index.tolist()\n",
    "    actor_matrix = actors_df[actors_df['actor_name'].isin(top_actors)].groupby(\n",
    "        ['movie_id', 'actor_name']\n",
    "    ).size().unstack(fill_value=0)\n",
    "    actor_matrix.columns = [f'actor_{c}' for c in actor_matrix.columns]\n",
    "    features = features.merge(actor_matrix, on='movie_id', how='left').fillna(0)\n",
    "    \n",
    "    top_directors = directors_df['director_name'].value_counts().head(30).index.tolist()\n",
    "    director_matrix = directors_df[directors_df['director_name'].isin(top_directors)].groupby(\n",
    "        ['movie_id', 'director_name']\n",
    "    ).size().unstack(fill_value=0)\n",
    "    director_matrix.columns = [f'director_{c}' for c in director_matrix.columns]\n",
    "    features = features.merge(director_matrix, on='movie_id', how='left').fillna(0)\n",
    "    \n",
    "    top_studios = studios_df['studio'].value_counts().head(20).index.tolist()\n",
    "    studio_matrix = studios_df[studios_df['studio'].isin(top_studios)].groupby(\n",
    "        ['movie_id', 'studio']\n",
    "    ).size().unstack(fill_value=0)\n",
    "    studio_matrix.columns = [f'studio_{c}' for c in studio_matrix.columns]\n",
    "    features = features.merge(studio_matrix, on='movie_id', how='left').fillna(0)\n",
    "    \n",
    "    # aggregate features\n",
    "    features['n_actors'] = actors_df.groupby('movie_id').size().reindex(features['movie_id']).fillna(0).values\n",
    "    features['n_directors'] = directors_df.groupby('movie_id').size().reindex(features['movie_id']).fillna(0).values\n",
    "    features['n_studios'] = studios_df.groupby('movie_id').size().reindex(features['movie_id']).fillna(0).values\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645208b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_embedding_dimensions(embeddings, n_components=50, name='embedding'):\n",
    "\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    reduced = pca.fit_transform(embeddings)\n",
    "    \n",
    "    _ = pca.explained_variance_ratio_.sum()\n",
    "    \n",
    "    return reduced, pca\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name, cv_folds=5):\n",
    "    cv_rmse = cross_val_score(model, X_train, y_train, cv=cv_folds, scoring='neg_root_mean_squared_error')\n",
    "    cv_r2 = cross_val_score(model, X_train, y_train, cv=cv_folds, scoring='r2')\n",
    "    \n",
    "    # Train on full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  CV RMSE: {-cv_rmse.mean():.4f} (+/- {cv_rmse.std():.4f})\")\n",
    "    print(f\"  CV R²:   {cv_r2.mean():.4f}\")\n",
    "    print(f\"  Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  Test MAE:  {test_mae:.4f}\")\n",
    "    print(f\"  Test R²:   {test_r2:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'cv_rmse': -cv_rmse.mean(),\n",
    "        'cv_r2': cv_r2.mean(),\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'test_r2': test_r2\n",
    "    }, model, y_pred\n",
    "\n",
    "\n",
    "def train_modality_models(X_train, y_train, X_test, y_test, X_train_scaled, X_test_scaled, modality_name):\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{modality_name.upper()} MODALITY\")\n",
    "    print('='*60)\n",
    "    \n",
    "    results = []\n",
    "    models = {}\n",
    "\n",
    "    ridge = Ridge(alpha=1.0)\n",
    "    res, model, _ = evaluate_model(ridge, X_train_scaled, y_train, X_test_scaled, y_test, 'Ridge Regression')\n",
    "    results.append(res)\n",
    "    models['ridge'] = model\n",
    "   \n",
    "    gb = GradientBoostingRegressor(n_estimators=50, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "    res, model, pred = evaluate_model(gb, X_train, y_train, X_test, y_test, 'Gradient Boosting')\n",
    "    results.append(res)\n",
    "    models['gb'] = model\n",
    "    \n",
    "    if 'text' in modality_name.lower() or 'image' in modality_name.lower():\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=300, early_stopping=True, \n",
    "                          random_state=42, learning_rate_init=0.001)\n",
    "        res, model, pred = evaluate_model(mlp, X_train_scaled, y_train, X_test_scaled, y_test, 'MLP Neural Network')\n",
    "        results.append(res)\n",
    "        models['mlp'] = model\n",
    "    \n",
    "    return results, models\n",
    "\n",
    "\n",
    "def late_fusion_stacking(X_cat_train, X_text_train_s, X_image_train_s, y_train,\n",
    "                         X_cat_test, X_text_test_s, X_image_test_s, y_test):\n",
    "\n",
    "    # Get out-of-fold predictions for training (prevents leakage)\n",
    "    print(\"\\nGenerating out-of-fold predictions...\")\n",
    "    pred_cat_train = cross_val_predict(\n",
    "        GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "        X_cat_train, y_train, cv=5\n",
    "    )\n",
    "    pred_text_train = cross_val_predict(\n",
    "        MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, early_stopping=True, random_state=42),\n",
    "        X_text_train_s, y_train, cv=5\n",
    "    )\n",
    "    pred_image_train = cross_val_predict(\n",
    "        MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, early_stopping=True, random_state=42),\n",
    "        X_image_train_s, y_train, cv=5\n",
    "    )\n",
    "    \n",
    "    # Create stacked feature matrix for training\n",
    "    X_stack_train = np.column_stack([pred_cat_train, pred_text_train, pred_image_train])\n",
    "    \n",
    "    # Fit final models to get test predictions\n",
    "    model_cat = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42).fit(X_cat_train, y_train)\n",
    "    model_text = MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, early_stopping=True, random_state=42).fit(X_text_train_s, y_train)\n",
    "    model_image = MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, early_stopping=True, random_state=42).fit(X_image_train_s, y_train)\n",
    "    \n",
    "    pred_cat_test = model_cat.predict(X_cat_test)\n",
    "    pred_text_test = model_text.predict(X_text_test_s)\n",
    "    pred_image_test = model_image.predict(X_image_test_s)\n",
    "    \n",
    "    X_stack_test = np.column_stack([pred_cat_test, pred_text_test, pred_image_test])\n",
    "    \n",
    "    # train meta-learner\n",
    "    meta_learner = Ridge(alpha=1.0)\n",
    "    results, _, y_pred = evaluate_model(meta_learner, X_stack_train, y_train, X_stack_test, y_test, 'Stacking Ensemble')\n",
    "    \n",
    "    print(f\"\\nMeta-learner weights: {meta_learner.coef_}\")\n",
    "    print(\"  (Weights correspond to: [Cat/Num, Text, Image])\")\n",
    "    \n",
    "    return results, meta_learner, y_pred, (pred_cat_test, pred_text_test, pred_image_test)\n",
    "\n",
    "\n",
    "def early_fusion(X_cat_train_s, X_text_train_s, X_image_train_s, y_train,\n",
    "                 X_cat_test_s, X_text_test_s, X_image_test_s, y_test):\n",
    "\n",
    "    # Concatenate all feature matrices\n",
    "    X_combined_train = np.concatenate([X_cat_train_s, X_text_train_s, X_image_train_s], axis=1)\n",
    "    X_combined_test = np.concatenate([X_cat_test_s, X_text_test_s, X_image_test_s], axis=1)\n",
    "    \n",
    "    print(f\"Combined feature matrix shape: {X_combined_train.shape}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Ridge: regularization for high-dim data, linear and suitable for tabular data\n",
    "    ridge = Ridge(alpha=10.0)\n",
    "    res, _, _ = evaluate_model(ridge, X_combined_train, y_train, X_combined_test, y_test, 'Ridge (Early Fusion)')\n",
    "    results.append(res)\n",
    "    \n",
    "    # MLP: can learn more complex cross-modal interactions, good for embeddings\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(256, 128, 64), max_iter=500, early_stopping=True, \n",
    "                       random_state=42, learning_rate_init=0.001)\n",
    "    res, _, y_pred = evaluate_model(mlp, X_combined_train, y_train, X_combined_test, y_test, 'MLP (Early Fusion)')\n",
    "    results.append(res)\n",
    "    \n",
    "    # Gradient Boosting, good for nonlinear relations and feature interactions\n",
    "    gb = GradientBoostingRegressor(n_estimators=150, max_depth=5, learning_rate=0.05, random_state=42)\n",
    "    res, _, _ = evaluate_model(gb, X_combined_train, y_train, X_combined_test, y_test, 'GB (Early Fusion)')\n",
    "    results.append(res)\n",
    "    \n",
    "    return results, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a626eb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (10599, 115)\n"
     ]
    }
   ],
   "source": [
    "movies_df, actors_df, directors_df, studios_df, poster_emb, tagline_emb, desc_emb = load_data()\n",
    "cat_num_features = create_features(movies_df, actors_df, directors_df, studios_df)\n",
    "print(f\"features shape: {cat_num_features.shape}\")\n",
    "\n",
    "poster_reduced, _ = reduce_embedding_dimensions(poster_emb, n_components=50, name='Poster')\n",
    "tagline_reduced, _ = reduce_embedding_dimensions(tagline_emb, n_components=50, name='Tagline')\n",
    "desc_reduced, _ = reduce_embedding_dimensions(desc_emb, n_components=50, name='Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46fa967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Combined text features: (10599, 100)\n",
      "  Image features: (10599, 50)\n",
      "Training set: 8479 samples\n",
      "Test set: 2120 samples\n"
     ]
    }
   ],
   "source": [
    "# Combine text embeddings\n",
    "text_features = np.concatenate([tagline_reduced, desc_reduced], axis=1)\n",
    "image_features = poster_reduced\n",
    "print(f\"\\n  Combined text features: {text_features.shape}\")\n",
    "print(f\"  Image features: {image_features.shape}\")\n",
    "\n",
    "# train/test split\n",
    "y = movies_df['rating'].values\n",
    "X_cat_num = cat_num_features.drop(['movie_id'], axis=1).values\n",
    "\n",
    "# split indices (same for all modalities to ensure consistency)\n",
    "indices = np.arange(len(y))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# split each modality\n",
    "X_cat_train, X_cat_test = X_cat_num[train_idx], X_cat_num[test_idx]\n",
    "X_text_train, X_text_test = text_features[train_idx], text_features[test_idx]\n",
    "X_image_train, X_image_test = image_features[train_idx], image_features[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "print(f\"Training set: {len(train_idx)} samples\")\n",
    "print(f\"Test set: {len(test_idx)} samples\")\n",
    "\n",
    "# scale features\n",
    "scaler_cat = StandardScaler()\n",
    "X_cat_train_s = scaler_cat.fit_transform(X_cat_train)\n",
    "X_cat_test_s = scaler_cat.transform(X_cat_test)\n",
    "\n",
    "scaler_text = StandardScaler()\n",
    "X_text_train_s = scaler_text.fit_transform(X_text_train)\n",
    "X_text_test_s = scaler_text.transform(X_text_test)\n",
    "\n",
    "scaler_image = StandardScaler()\n",
    "X_image_train_s = scaler_image.fit_transform(X_image_train)\n",
    "X_image_test_s = scaler_image.transform(X_image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecaf7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6026a61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CATEGORICAL/NUMERICAL MODALITY\n",
      "============================================================\n",
      "\n",
      "Ridge Regression:\n",
      "  CV RMSE: 0.3966 (+/- 0.0071)\n",
      "  CV R²:   0.2832\n",
      "  Test RMSE: 0.3956\n",
      "  Test MAE:  0.2935\n",
      "  Test R²:   0.2745\n",
      "\n",
      "Gradient Boosting:\n",
      "  CV RMSE: 0.3738 (+/- 0.0072)\n",
      "  CV R²:   0.3633\n",
      "  Test RMSE: 0.3681\n",
      "  Test MAE:  0.2694\n",
      "  Test R²:   0.3720\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Categorical/Numerical modality\n",
    "cat_results, _ = train_modality_models(\n",
    "    X_cat_train, y_train, X_cat_test, y_test,\n",
    "    X_cat_train_s, X_cat_test_s, \"Categorical/Numerical\"\n",
    ")\n",
    "best_cat = min(cat_results, key=lambda x: x['test_rmse'])\n",
    "best_cat['model_name'] = 'Cat/Num (Best)'\n",
    "all_results.append(best_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b820e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEXT (EMBEDDINGS) MODALITY\n",
      "============================================================\n",
      "\n",
      "Ridge Regression:\n",
      "  CV RMSE: 0.4235 (+/- 0.0093)\n",
      "  CV R²:   0.1826\n",
      "  Test RMSE: 0.4235\n",
      "  Test MAE:  0.3157\n",
      "  Test R²:   0.1687\n"
     ]
    }
   ],
   "source": [
    "# Text modality\n",
    "text_results, _ = train_modality_models(\n",
    "    X_text_train, y_train, X_text_test, y_test,\n",
    "    X_text_train_s, X_text_test_s, \"Text (Embeddings)\"\n",
    ")\n",
    "best_text = min(text_results, key=lambda x: x['test_rmse'])\n",
    "best_text['model_name'] = 'Text (Best)'\n",
    "all_results.append(best_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f2b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image modality\n",
    "image_results, image_models = train_modality_models(\n",
    "    X_image_train, y_train, X_image_test, y_test,\n",
    "    X_image_train_s, X_image_test_s, \"Image (Embeddings)\"\n",
    ")\n",
    "best_image = min(image_results, key=lambda x: x['test_rmse'])\n",
    "best_image['model_name'] = 'Image (Best)'\n",
    "all_results.append(best_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e2f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi modal fusion\n",
    "# late fusion (stacking)\n",
    "stack_results, meta_model, y_pred_stack, individual_preds = late_fusion_stacking(\n",
    "    X_cat_train, X_text_train_s, X_image_train_s, y_train,\n",
    "    X_cat_test, X_text_test_s, X_image_test_s, y_test\n",
    ")\n",
    "all_results.append(stack_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7cbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early fusion\n",
    "early_results, y_pred_early = early_fusion(\n",
    "    X_cat_train_s, X_text_train_s, X_image_train_s, y_train,\n",
    "    X_cat_test_s, X_text_test_s, X_image_test_s, y_test\n",
    ")\n",
    "best_early = min(early_results, key=lambda x: x['test_rmse'])\n",
    "all_results.append(best_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple averaging baseline\n",
    "pred_avg = sum(individual_preds) / 3\n",
    "avg_results = {\n",
    "    'model_name': 'Simple Average',\n",
    "    'cv_rmse': None,\n",
    "    'cv_r2': None,\n",
    "    'test_rmse': np.sqrt(mean_squared_error(y_test, pred_avg)),\n",
    "    'test_mae': mean_absolute_error(y_test, pred_avg),\n",
    "    'test_r2': r2_score(y_test, pred_avg)\n",
    "}\n",
    "all_results.append(avg_results)\n",
    "print(f\"  Test RMSE: {avg_results['test_rmse']:.4f}\")\n",
    "print(f\"  Test R^2:   {avg_results['test_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from plotting import (\n",
    "plot_model_comparison_dashboard,\n",
    "plot_predictions_analysis,\n",
    "plot_modality_contribution,\n",
    "create_summary_slide\n",
    ")\n",
    "\n",
    "plot_model_comparison_dashboard(all_results, \"model_dashboard.png\")\n",
    "plot_predictions_analysis(y_test, y_pred_stack, 'Stacking Ensemble', \"prediction_analysis.png\")\n",
    "plot_modality_contribution(individual_preds, y_test, meta_model.coef_, \"modality_contribution.png\")\n",
    "create_summary_slide(all_results, 'Stacking Ensemble', y_pred_stack, y_test, \"summary_slide.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modulai-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
